{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMQUSsxGt8pY",
        "outputId": "f8325254-7e39-4ea5-a2ad-0b72f580478c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output video saved at: finalized.mp4\n"
          ]
        }
      ],
      "source": [
        "# Final as of now good\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Path to the input video file (update as needed)\n",
        "video_path = '/content/drive/MyDrive/Avawatz/internship documentation/D28_20231018123011.mp4'\n",
        "\n",
        "# Path to the output video file (update as needed)\n",
        "output_path = 'finalized.mp4'\n",
        "\n",
        "# Create a VideoCapture object to read the input video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Create a background subtractor using the GMM model (MOG2)\n",
        "background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
        "\n",
        "# Get video frame properties (width, height, frames per second)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define the codec and create a VideoWriter object to save the output video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4 format\n",
        "output_video = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Calculate the number of frames for the first 30 seconds\n",
        "frame_limit = int(fps * 30)  # fps * 30 seconds\n",
        "\n",
        "# Frame counter to track the number of frames processed\n",
        "frame_counter = 0\n",
        "\n",
        "# Create a structuring element for morphological operations\n",
        "kernel = np.ones((3, 3), np.uint8)\n",
        "\n",
        "# Main loop to read frames and perform background subtraction\n",
        "while cap.isOpened() and frame_counter < frame_limit:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break  # Exit the loop if no frame is retrieved (end of video)\n",
        "\n",
        "    # Apply background subtraction to the frame\n",
        "    fg_mask = background_subtractor.apply(frame)\n",
        "\n",
        "    # Convert the mask to binary (thresholding) for better results\n",
        "    _, fg_mask = cv2.threshold(fg_mask, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Apply morphological erosion to the binary mask to reduce noise\n",
        "    fg_mask = cv2.erode(fg_mask, kernel, iterations=2)  # Apply erosion twice\n",
        "\n",
        "    # Apply morphological dilation to the binary mask to smooth the mask\n",
        "    fg_mask = cv2.dilate(fg_mask, kernel, iterations=7)  # Apply dilation\n",
        "\n",
        "    # Use the mask to extract the foreground from the original frame\n",
        "    foreground = cv2.bitwise_and(frame, frame, mask=fg_mask)\n",
        "\n",
        "    # Add text based on motion detection\n",
        "    if np.sum(fg_mask) > 0:\n",
        "        text = \"Motion\"\n",
        "    else:\n",
        "        text = \"No Motion\"\n",
        "    cv2.putText(foreground, text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    # Save the foreground frame to the output video\n",
        "    output_video.write(foreground)\n",
        "\n",
        "    # Increment the frame counter\n",
        "    frame_counter += 1\n",
        "\n",
        "# Release the VideoCapture and VideoWriter objects\n",
        "cap.release()\n",
        "output_video.release()\n",
        "\n",
        "# Output message indicating the saved output video file\n",
        "print(f'Output video saved at: {output_path}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vEc6suVWuaC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce287a31-2135-487b-af66-a34a712e8ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}